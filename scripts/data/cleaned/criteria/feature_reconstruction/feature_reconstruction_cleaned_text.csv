text
several different type of information were extracted from the collected instagram data we used total post per user per day a a measure of user activity we gauged community reaction by counting the number of comment and like each posted photograph received face detection software wa used to determine whether or not a photograph contained a human face a well a count the total number of face in each photo a a proxy measure for participant social activity level pixellevel average were computed for hue saturation and value hsv three color property commonly used in image analysis hue describes an image coloring on the light spectrum ranging from red to bluepurple lower hue value indicate more red and higher hue value indicate more blue saturation refers to the vividness of an image low saturation make an image appear grey and faded value refers to image brightness lower brightness score indicate a darker image see figure for a comparison of high and low hsv value we also checked metadata to ass whether an instagramprovided filter wa applied to alter the appearance of a photograph collectively these measure served a the feature set in our primary model for the separate model fit on rating data we used only the four rating category happy sad likable interesting a predictor
our first set of method include developing three set of measure spanning linguistic structure interpersonal awareness and interaction the choice of these measure is motivated by literature that examines association between the behavioral expression of individual and their response to crisis including vulnerability due to mental illness each of these measure category consists of the following variable linguistic structure for this measure we compute the fraction of noun verb and adverb in post and comment automated readability index a measure to gauge the understandability of text and linguistic accommodation a process by which individual in a conversation adjust their language style according to that of others together these variable characterize the text shared by the user class beyond their informational content per literature in psycholinguistics such structure is known to relate to an individual underlying psychological and cognitive state and can reveal cue about their social coordination interpersonal awareness this measure category includes proportion of first person singular indicating preoccupation with self first person plural indicating collective attention second person and third person pronoun indicating social interactivity and reference to people or object in the environment literature ha indicated that pronoun use can quantify an individual self and social awareness and can reveal mental wellbeing including that manifested in social medium interaction variable corresponding to this measure category include volume of post and comment authored post length length of comment authored volume of comment received on shared post length of comment received mean vote difference difference between upvotes and downvotes on post authored and response velocity in minute given by the time elapsed between the first comment and the time the corresponding post wa shared
based on the training data thus created we pursued the use of supervised learning to develop a classifier which would indicate whether a post is of high low or no selfdisclosure we tested a variety of different classification technique decision tree k nearest neighbor naive bayes the best performing classifier wa found to be a perceptron classifier with adaptive boosting used to amplify performance whose result will be used in the remainder of this paper we used the following feature generation rule first we eliminated stopwords from each post based on standard list provided by python nltk library next we performed stemming using porter stemmer we extracted uni bi and trigram from each post and considered those with five or more occurrence we also computed two additional feature length of each post and whether the author of the post is an exclusive poster on mental health forum or is observed in our dataset to post on other forum a well thus each post wa characterized by feature we used standard fold cross validation cv to evaluate the classifier and ran our model over random fold cv assignment for generalizability of the result we report the average accuracy precision recall f specificity a metric of performance we find that our classifier based on the perception model yield an average accuracy of in detecting high or low selfdisclosure with precision and recall see table for detail other method like knn k give higher precision but at the expense of very low recall figure give the roc receiver operating characteristic curve for all the model per the roc curve corresponding to the perceptron model we find it to yield the maximum area under curve hence best performance we further identify in table the ngrams or feature with the highest weight given by the perceptron it implies these feature were the most significant in the classification task we provide some brief qualitative examination of these ngrams in the light of prior psychology literature on selfdisclosure and mental health we find that the ngrams primarily are associated with vulnerable and selfloathing thought eg thought of suicide bear a negative tone or depict confessional experience based on prior research and our own work on mental health discourse on reddit we find that these are the topical dimension along which high selfdisclosure and lowno selfdisclosure post vary in essence high selfdisclosure post share extensively their personal belief and fear for instance their vital construct and private sensitive informational attribute the post excerpt below have been classified to be of high selfdisclosure and through them we demonstrate the use of some of the ngrams in table i dont want to kill myself i havent felt suicidal in a long time but i just want to stop life for a while you know my dad would beat the living shit out of me ive been to the hospital so many time ive lost track i hate this i hate myself i dont want to f be this person anymore im unmotivated unfocused immature
it is possible to extract various feature from the activity history of twitter user this section explains what kind of feature are used to estimate degree of depression and the way in which these quantity are extracted table show the feature used in this study a detailed explanation of each feature follows the frequency of word in a tweet ie it bag of word are used a a basic feature relating to the content of the tweet tsugawa et al showed that the word frequency are useful for identifying depression mecab wa used to for morphological stemming and categorization of the japanese tweet text to obtain accurate word frequency particle auxiliary verb adnominal adjective and visual symbol were excluded for extracting content word word used by only one participant were also excluded resulting in a total of distinct word however most of these word were rarely used and the distribution of word frequency is extremely biased see fig because word with a low rate of use were regarded a unlikely to be associated with depression for most user the frequency of only the word with the highest rate of use corresponding to or more us across all participant were used a a feature in this study furthermore because the number and length of tweet differed by participant the word frequency were normalized by the total number of word in the tweet the topic of the tweet of each user a estimated by using a representative topic model lda were used a a second feature relating to the content of the tweet with lda the distribution of topic in each document is estimated from the word frequency in each text through unsupervised learning on the assumption that the text and the word in it are generated according to a particular topic in lda the number of topic to identify and a set of document a bag of word are used a input and a topic distribution is output for each document a mentioned in related work section the topic of essay written by university student were estimated by using lda and found to be useful in evaluating degree of depression from that study topic are expected to be a useful feature a set of all tweet of each user wa used a the user document for input in lda and the word selected a described above were used a the word we used lda with collapsed gibbs sampling a the parameter of lda we used k and where k is the number of topic all extracted topic were used a the feature the ratio of positive word and the ratio of negative word used in the tweet text are used a the final feature relating to tweet content user with depression are intuitively expected to use negative word more frequently than user without depression do to categorize word a dictionary of affective word which is compiled by manual evaluation of a dictionary of positive and negative word extracted according to a technique proposed in the literature is used the dictionary contains positive word and negative word the user timing of tweet frequency of tweet average number of word retweet rate rate of republishing other user tweet mention rate rate of directly referencing at least one other user ratio of tweet containing a uniform resource locator url number of user being followed and number of user following are used a feature independent of the content of the tweet the relative ratio of tweet posted during each hour of the day were used to characterize the timing of tweet the number of post per day wa used a the posting frequency and the ratio of qualifying tweet to all tweet were used for the retweet ratio mention ratio and ratio of tweet containing a url these feature are used in prior research
in an effort to minimize noisy and unreliable data we applied several quality assurance measure in our data collection process mturk worker who have completed at least task with a minimum approval rating have been found to provide reliable valid survey response we restricted survey visibility only to worker with these qualification survey access wa also restricted to u ip address a mturk data collected from outside the united state are generally of poorer quality all participant were only permitted to take the survey once we excluded participant with a total of fewer than five twitter post we also excluded participant with cesd score of or lower depression or tsq score of or lower ptsd study have indicated that a cesd score of represents an optimal cutoff for identifying clinically relevant depression an equivalent tsq cutoff of ha been found to be optimal in the case of ptsd we note here that in the study that inspired the present work de choudhury et al used two depression scale cesd and bdi and filtered individual whose depression score did not correlate across the both scale this additional criterion is a methodological strength of de choudhury et al with respect to the present work
we estimated userlevel degree of depression ddep a the average response to seven depression facet item which are nested within the larger neuroticism item pool for each item user indicated how accurately short phrase described themselves eg often feel blue dislike myself response ranged from very inaccurate to very accurate figure a show the distribution of surveyassessed ddep standardized the item can be seen in table figure show the daily average of surveyassessed ddep collapsed across year a loess smoother over the daily average illustrates a seasonal trend with depression rising over the winter month and dropping during the summer
to characterize the difference between clinical and control community a variety of feature are extracted affective feature we use the lexiconaffective norm for english word anew to extract the sentiment conveyed in the content this lexicon consists of word rated in term of valence and arousal and is thus suitable for a quantitative estimation the valence of anew word is on a scale of very unpleasant to very pleasant the arousal is measured on the same scale least active to most active a cloud visualization of anew word used in the blog post made by clinical and control group is illustrated in fig mood tag livejournal provides a mechanism for user to tag their post from a list of predefined mood label thus in addition to the emotion expressed in the text of post the mood tag produced allows u direct access to the user sentiment a cloud visualization of mood tagged on blog post made by clinical and control community is llustrated in fig liwc feature we examine the proportion of word in psycholinguistic category a defined in the liwc package linguistic social affective cognitive perceptual biological relativity personal concern and spoken table present the mean of these liwc psycholinguistic process for the clinical and control community whilst similar in the use word with positive emotion people in the clinical community tend to use word with more negative emotionas example anxiety anger and sadness further they discus more issue about health and death in comparison with the control group on the other hand the user in the control group discus more neutral life related topicsingestion home and leisure word topic for extracting topic latent dirichlet allocation lda is used a a bayesian probabilistic modelling framework lda extract the probability that is word in a topic and then assigns a topic to each word in a document for the inference part we implemented gibbs inference detailed in we set the number of topic to run the gibbs for sample and use the last gibbs sample to interpret the result
weibo post were segmented using the stanford word segmenter that resulted in word and phrase thereafter the scliwc dictionary wa applied to count the appearance of each category of word in every respondent weibo post the scliwc dictionary includes word that are grouped into category including main linguistic or psychological category and subcategories in addition the total number of word or phrase that each respondent published in the month wa counted a the nd category score of the scliwc category were counted a percentage of the total number of word
we now present a methodology of identifying post shared in university subreddits that that are likely to be mental health expression note that our reddit data doe not contain any gold standard information around whether a post shared in a university subreddit is about one mental health experience or condition our proposed method overcomes this challenge by employing an inductive transfer learning approach first we include a ground truth data reddit post made on various mental health support community prior work ha established that in these community individual selfdisclose a variety of mental health challenge explicitly parallelly we utilize another set of reddit post made on generic subreddits unrelated to mental health to be a control next we build a machine learning classifier to distinguish between these two type of post then we learn feature that could detect whether an post shared in a university subreddit could be an expression of some mental health concern we discus these step in detail in the following subsection
in this work we are focused on two main type of feature linguistic and behavioral tfidf is adopted to model the linguist feature of patient and pattern of life feature plf adopted from the work of coppersmith et al is used to model the behavioral style of patient tfidf feature to capture the frequent and representative word used by the patient tfidf is applied on the unigram and bigram collected from all the patient tweet pattern of life feature plf these feature reveal the emotional pattern and behavioral tendency of user by measuring polarity emotion and social interaction in order to fully compose the plf we combined the following list of feature age and gender twitter doe not publicly provide information about the age and gender of it user mainly due to privacy concern so we adopted the work of sap et al to fill in this information polarity feature the sentiment api wa used to label each tweet a either positive negative or neutral the polarity is furthermore transformed into five different value to capture the affective trait of each user positive ratio the percentage of positive tweet negative ratio the percentage of negative tweet positive combo capture the mania and hypomania trait of patient which is determined by the number of continuous positive post appearing more than x amount of time within a period of time in minute t negative combo capture the depression trait of patient and is determined by the number of continuous negative post appearing more than x amount of time within a period of time in minute t flip ratio quantifies the emotional unstableness and is determined by counting how frequently two continuous tweet with different polarity either positive to negative or negative to positive appear together within a period of time in minute t in our work x is set to and t is set to minute social feature these feature can demonstrate how user are behaving with respect to their environment the following are the social feature designed for each user tweeting frequency the frequency of daily post mention ratio the percentage of post which contain at least one mention of another user frequent mention the number of twitter user mentioned more than three time which is a measurement of how many close friend a particular user may have unique mention the number of unique user mentioned which is a measure of the width of a user social network
the data preprocessing procedure for the collected post data is presented in fig after collecting the data each title wa combined with it corresponding post we removed unnecessary punctuation mark and white space for each post then we used the natural language toolkit nltk implemented in python to tokenize user post and filter frequently employed word stop word porter stemmer a tool used to define a series of guideline for exploring word meaning and source wa employed on the tokenized word to convert a word to it root meaning and to decrease the number of word corpus after this procedure data from user with post in total were employed for the analysis
our cohort construction process entail two key step first randomly selecting a large sample of twitter user and second annotating those user with key demographic attribute while such attribute are not provided by the api automated method can be used to infer such trait from data cesare et al following this approach we develop a demographic inference pipeline to automatically infer age gender raceethnicity and location for each cohort candidate age identifying age based on the content of a user can be challenging and exact age often cannot be determined based on language use alone therefore we use discrete category that provide a more accurate estimate of age teenager below s s s s year or older gender the gender wa inferred using demographer a supervised model that predicts the binary gender of twitter user with feature based on the name field on the user profile knowles et al raceethnicity the standard formulation of race and ethnicity is not well understood by the general public so categorizing social medium user along these two ax may not be reasonable therefore we use a single measure of multicultural expression that includes five category white w asian a black b hispanic h and other location the location wa inferred using carmen an opensource library for geolocating tweet that us a series of rule to lookup location string in a location knowledgebase dredze et al we use the inferred location to select user that live in the united state the age and raceethnicity attribute were inferred with custom supervised classifier based on amir et al s userlevel model the classifier were trained and evaluated on a dataset of k annotated user attaining performance of and average f respectively see the supplemental note for additional detail on these experiment
first we removed journal with no text and those with fewer than character leaving million journal for topic modelling next we preprocessed the text using the stanford tweet tokenizer which is a twitteraware tokenizer designed to handle short informal text we used the option that truncates character repeating or more time converting phrase such a im sooooo happyy to im soo happyy on average the number of token per journal wa since we are interested in topic we removed stopwords and token with fewer than two letter and we only retained noun which appear in the wordnet corpus after this filtering the average number of noun per journal wa example of frequently appearing noun in alphabetical order include anxiety class dinner family god job lunch miss school sick sleep and work we then iteratively clustered the journal into topic detail below and removed noun that do not refer to topic such a number timing eg today yesterday general feeling eg feel like proper noun and noun that have ambiguous meaning eg overall true lastly we only retained noun that appeared more than ten time in the dataset this process resulted in a vocabulary of word for topic modelling each journal is represented a a dimensional term frequency vector with each component denoting the termfrequency inversedocumentfrequency tfidf of the corresponding term algorithm summarizes our topic modelling methodology given a tfidf term frequency vector for each journal we run nonnegative matrix factorization nmf implemented in python scikitlearn package the objective of nmf is to find two matrix whose product approximates the original matrix in our case one matrix is the weighted set of topic in each journal and the other is the weighted set of word that belong to each topic hence each journal is represented a a combination of topic which are themselves composed of a weighted combination of word we chose nmf because it nonnegativity constraint aid with interpretability in the context of analyzing word frequency negative presence of a word would not be interpretable this is because we only track word occurrence and not semantics or syntax unlike other matrix factorization method nmf reconstructs each document from a sum of positive part which enables u to easily manually label the discovered topic iterating from to topic we derived different topic matrix step and of algorithm each matrix consists of one topic per row each topic ha a positive weight for each word in the vocabulary stronger weight indicate higher relevance to the topic the final topic matrix we used ha topic and is shown in table we show the first six word in this table for simplicity where we sorted the word associated with each topic from highest relevance to lowest when judging the topic matrix we considered the top twenty most important word per topic using this information we manually labeled each row in the matrix with a corresponding topic furthermore we manually evaluated each matrix based on the distinctness between topic consistency within topic and interpretability during this process we compiled a custom list of removed word that we mentioned earlier in this section the group of word we removed appeared a standalone topic that did not offer information about what the journal wa about for example proper noun appeared a a standalone topic other word which we deemed too general or ambiguous appeared across several topic and hence did not provide discriminative information we tested different level of regularization to enforce sparseness in our model see for a discussion but did not find significant difference however one important modification we made to regularize each topic wa to make their first word only a strong a their second one by default first word are stronger than second word which are stronger than third word and so on this is since the most relevant word for each topic tended to be too strong of a signal regardless of how we changed the number of topic preprocessing procedure or regularization in the objective function for example the word love in a journal about sport would be so strong that the journal would be labeled a relating to romantic love lowering the importance of first word wa sufficient to eliminate the false positive we identified given the final topic matrix summarized in table the next step is to use it to assign label to journal step and of algorithm we plotted the distribution of how important each topic wa to all journal in the dataset with importance ranging from zero to one each distribution had a similar shape with a clear inflection point between to importance figure show an example importance distribution for the topic work where the inflection point occurs at importance
we first introduce several measure used in our analysis relative use for a given health condition it relative use on twitter or the search engine is given by the ratio of it volume of use in that medium to the volume of the health term that is most used in that medium for example the most searched condition on the search engine wa cancer appearing in query and the secondmost queried wa pregnancy found in query the relative use for cancer on the engine it wa for pregnancy rank a relative ranking based on normalized relative mention of a health condition on twitter or the search enginelower rank mean greater use for example on twitter the mostused term from our list is headache that appeared in post it would receive a rank rank difference we compute rank difference between the search engine and twitter for each health term large negative value indicate that a term is searched relatively more than tweeted whereas large positive value mean the reverse for example cough ha rank on twitter and rank on the search engine it rank difference is reflecting it relative prominence on twitter a compared to search based on these definition in table we report the top most searched and most shared health condition in term of their rank and relative use on each platform the table also show the top most positive rank difference relatively more tweeted than searched and most negative rank difference relatively more searched than tweeted condition along with severitytype and stigma level of each condition
to understand the nature of selfdisclosure in reddit post we first examine the general linguistic attribute manifested in their content in table we first present a list of the most popular stopword eliminated unigrams that appear in reddit posting we intended to look at these highly shared unigrams more deeply and systematically hence we organized these unigrams stopword inclusive in various semantic category provided by the psycholinguistic lexicon liwc httpwwwliwcnet we find that among the unigrams in table there are word that extensively span emotional or affective expression happy love bad anxiety good hate eg ive been recently wondering if my love to numb the world around me ha turned me into an alcoholic ha anyone else battled numbness loss of feeling during recovery doe it ever get better ive been sober for about year and still have pretty severe anxiety at time we observe presence of relationship and social life word too family friend people person parent eg i get really anxious out when i go home for big event i do love my family theyre just really loud and argumentative sometimes temporal indicator in reddit discourse is also visible eg time day year month hi all im ten week sober today and while i wish i could say im physically and mentally in great shape the truth is i judge my day by how i feel le bad a oppose to good work and daily grind oriented word are common a well because lifestyle irregularity are often associated with the psychopathology of mental illness prigerson et al eg life school work job i am completely broke cant afford rehab and cant take time off work we also find a fair number of cognitive word in these highly used unigrams felt hard feeling lot eg im new here but having anxiety like i havent felt in a long time i find a lot of strength in going to a concert i have been understanding of my anxiety and depression since i wa about and i hated it these observation are supported by psychology literature where cognitive bias a manifested through dysfunctional attitude depressive attributional bias and negative automatic thought were found to be characteristic of mental illness eaves rush further inhibition word like avoid deny safe demonstrate that redditors are perhaps using the platform to broadcast their thought to an audience of stranger or weak tie on issue and topic they might consider to be socially stigmatic to be discussed elsewhere i cant escape the feeling of fright i have at all time i dont feel safe in my own home ive been denying my assumed depression symptom for close to two year now writing them off comparing across different liwc semantic category over all post we observe noticeable difference kruskalwallis oneway analysis of variance indicated the difference across category to be significant n p table report the top most common liwc category the mean proportion of word from each category in the post and the corresponding standard deviation note that the percentage over all category sum to greater than since a word could belong to multiple category observing closely many of the category whose corresponding unigrams appeared in table are also highly prominent category globally over all post a given in table not shown in table perhaps intuitively negative emotion anger and sadness word were considerably more prominent than positive emotion word a wilcoxon signed rank test reveals that the difference are statistically significant z p likely these redditors experience several negative emotion hence mental instability helplessness loneliness restlessness manifest in their posting rude et al the health and social issue they are facing in fact high selfattentional focus is a known psychological attribute of mental illness sufferer chung pennebaker
towards our first research goal rq to examine the visual feature of image relating to mental health disorder we employ the extraction of color profile ie grayscale histogram grayscale histogram provide u intuition about the brightness saturation and contrast distribution of image in these histogram image with high contrast pixel are binned in bin with lower number near whereas image with brighter pixel are binned in higher number bin near we utilize the opencv library to extract these color histogram of image in our dataset we also ass the visual saliency of image using opencv a distinct subjective perceptual quality that make some image stand out from their neighbor a typical image in our dataset is of size px px so by using a saliency metric we obtain a grid matrix for each image in these three visual feature category we obtain an empirical threshold that ensures rd of the pixel will be greater than this value when sorted based on their saliency
tweet about depression were collected by simply measured a company that specializes in social medium measurement and analytics simply measured simply measured ha access to the twitter firehose or full volume of tweet via gnip a licensed company that can retrieve the full twitter data stream all tweet in the english language that contained at least either depressed depressed depression or depression were collected between april and may we scanned a random sample of the tweet to identify common phrase that included our keywords of interest but were not about mental health in sa version sa institute inc cary nc we used the index function which search a character expression in this case the text of the tweet for a specific string of character to locate and remove such tweet from our sample we removed tweet that included the following term regardless of capitalization great depression economic depression during the depression depression era tropical depression and depressed real estate the popularity and influence of the tweeter wa described using the distribution of follower and klout score while number of follower is a measure of popularity klout score is a measure of influence klout score range from to with a higher score indicating higher influence klout score is calculated based on an algorithm that considers over signal from eight different online network example of signal include the amount of retweets a person generates in relation to the amount of tweet shared and the amount of engagement a user drive from unique individual eg lot of retweets from different individual a opposed to lot of retweets from one person klout inc
character ngram language model are model built on sequence ngrams of character here we use gram for all the tweet a user authored we count the number of time each sequence of character is observed for example for this sentence we would observe the sequence for e or ex r exa exam and so on the general approach is to examine how likely a sequence of character is to be generated by a given type of user schizophrenic or nonschizophrenic to featurize character ngrams for each character gram in the training data we calculate it probability in schizophrenic user and it probability in control user at test time we search for set of sequential tweet that look most schizophrenic by comparing the schizophrenic and control probability estimated from the training data for all the gram in those tweet we experimented with different window size for the number of tweet and different n for ngrams for brevity we report only the highest performing parameter setting at low false alarm rate gram and a window size of tweet an example of this can be found in figure where one schizophrenic and one control user score over time is plotted top to show the overall trend we plot the same for all user in this study bottom where separation between the schizophrenic in red and control user in blue is apparent the highest score from this windowed analysis becomes the feature value note that this feature corresponds to only a subset of a user timeline for schizophrenia sufferer this is perhaps when their symptom were most severe a subtle but critical distinction when one considers that many of these people are receiving treatment of some sort and thus may have their symptom change or subside over the course of our data
next we compiled a list of reported celebrity suicide which fell within the time range of our reddit data defining who is a celebrity is nontrivial so we refer to the wikipedia page listing celebrity suicide a a way to measure who ha sufficient celebrity status for inclusion we obtained reported celebrity suicide in the same period a our reddit data their name and reported suicide are shown in table we measure the prominence of a celebrity death by measuring the change in wikipedia page view for the celebrity wikipedia page wikipedia provides daily page view statistic for each page we compare the number of pageviews in the two week prior to their death with the two week following their death in term of zscore figure here zscores are computed by converting the page view to standard normal variable with mean and standard deviation of for of the case we see a notable spike in number of view showing that the suicide of these individual were wellknown enough to be viewable on such a macro scale and for examining the presence of werther effect in social medium we note two aspect related to the above analysis and which will be used through the rest of this paper first since we are focusing on different type of data sourceswikipedia and reddit we use zscore conversion a a normalization technique for the wikipedia page view and reddits sw posting activity volume further the above observation in wikipedia data and the analysis that ensue focus on observing change over a two week window preceding and succeeding a celebrity suicide this choice is motivated by our initial analysis and from the literature on werther effect
this study aimed to examine the prevalence of affective micropatterns in social medium post and highlight difference in micropattern occurrence that might be relevant to quantifying mental health primarily we do this through comparison of user with anxiety disorder eating disorder schizophrenia suicide attempt history and their matched control we use a straightforward and wellunderstood method for sentiment analysis vader hutto and gilbert to produce a trinary label for each message positive neutral or negative vader output a score for each sentiment label we use the label with the maximum score specifically we examined trajectory of posted emotional content in three subsequent tweet no more than three hour from earliest to latest the same tweet will be counted in more than one over lapping micropattern if more than three tweet occur in the threehour time window so if tweet occur in hour micropatterns will be recorded from those tweet likewise for tweet micropatterns will be recorded the potential overlap exists for both patient and neurotypical user and subsequent analysis eg classifying user based on proportion of micropatterns were designed to be robust to this property of overlapping micropattern generation the number of sequential tweet to examine wa chosen to minimize the complexity of the analysis while allowing significant variability to be observed critically we aimed for the resulting dimension ie number of distinct micropatterns to be small enough for meaningful interpretation by clinical psychologist
in this subsection we present method to quantify the difference between the disclosure characteristic of female and male and individual reported to be from one of the four country of interest u gb in and za in the mid dataset linguistic measure language is a powerful source of expression a rich body of work such a boroditsky et al showed how the perception of object in different language can relate to a well a impact one social and pscyhological status it is recognized that language specifically one native language shape and drive one thought action and social relationship further it is established that crosscultural and sex difference exist in one underlying thought process for instance according to kovecses cultural model are known to define one emotional concept to quantify gender and crosscultural dimension in the language of individual who engage in mental health disclosure on social medium we propose three category of measure affective attribute cognitive attribute and linguistic style attribute measure belonging to all of these attribute category are largely based on the psycholinguistic lexicon liwc and were motivated from prior literature that examines association between the behavioral expression of individual and their psychological distress including vulnerability to mental illness specifically with liwc we are able to study the psychological value of language in gender and culture subgroupssuch a part of speech that include pronoun article preposition conjunctive and auxiliary verb we consider two measure of affect derived from liwc positive affect pa and negative affect na and four other measure of emotional expression anger anxiety sadness and swear literature in mental health identifies emotional expression to be key to characterizing one psychological vulnerability we use liwc to define the cognitive measure a well a cognition comprising cognitive mech discrepancy inhibition negation death causation certainty and tentativeness and b perception comprising set of word in liwc around see hear feel percept insight and relative quantifying one cognition and perception a manifested linguistically can provide insight into emotional stability and cognitive complexitythese attribute are important with regard to understanding one mental wellbeing next we consider four measure of linguistic style a lexical density consisting of word that are verb auxiliary verb noun adjective identified using nltks po tagger and adverb b temporal reference consisting of past present and future tense c socialpersonal concern word belonging to family friend social work health human religion bio body money achievement home and sexual d interpersonal awareness and focus word that are st person singular st person plural nd person and rd person pronoun together linguistic style are known to indicate one underlying psychological process lexical density personality temporal reference social support and connectivity socialpersonal concern and awareness of one surroundings and environment interpersonal focus prior work identifies all of these cue to be valuable in understanding mental health in both offline and online context including social medium topic modeling our second method for comparing mental illness disclosure us a topic model which have been commonly employed to analyze health data we obtain topic by running latent dirichlet allocation lda over all post we preprocessed the data by removing a standard list of twitterspecific stop word word with very high frequency datasize and word that occur fewer than five time thereafter we used gensims implementation of online lda from we used the default hyperparameter setting and topic which we determined based on the value of average corpus likelihood over ten run to measure topic difference in one cohort eg in mid user over the other eg uk mid user we first compute the posterior probability of each topic separately for all post in both cohort we then compute three comparison metric the rate of change for each topic given a the difference between the posterior topic probability of the cohort divided by the probability of the first cohort the pointwise mutual information between the posterior topic probability of the same cohort and the spearmans rank correlation between the topic distribution for the two cohort additionally we compare all gender and culture cohort based on significance test eg mann whitney u test for gender and the kruskal wallis test for cultural difference we also present a method to qualitatively examine the difference between the topic used by different mid user cohort for the purpose two researcher familiar with mental health content on social medium independently inspected the word associated with each of the topic given by the above topic model they used a semiopen coding approach to develop a codebook and extracted descriptive topical theme for the topic cohens during the codebook development the two annotator referred to prior literature on gender and cultural difference in mental health in the result section we will present an examination of these qualitative difference
the selection of the tweet and their user wa based on the filtered realtime streaming support provided by the twitter api in the first step we selected the user who showed potential sign of depression on twitter on the basis of the most frequent word in spanish expressed by patient suffering from depression in clinical setting these word were jointly identified and selected by a psychologist and a family physician with clinical experience and were based on the definition and general feature of depression according to the diagnostic and statistical manual of mental disorder the list of word used and their english translation are shown in textbox during june tweet including or more occurrence of the word listed in textbox were collected from this collection of tweet and to select the user who publicly stated in the textual description associated to their profile that they suffered from depression all the profile description including or more occurrence of the word depr and all the possible derivation related to the word depression in spanish such a depre depresin depresivo depresiva deprimido and deprimida were considered from the user who included or more of these word in their description profile user who stated they suffered from depression or were receiving treatment for depression were selected for the analysis this selection wa performed by a psychologist verifying that the statement were related to real expression of depression excluding quote joke or fake one for each of these depressed twitter user we collected all the most recent tweet from their timeline up to a maximum of about tweet thus a total of tweet were collected a figure that wa reduced to after discarding the retweets these tweet constituted the depressive user dataset example of sentence appearing in the user profile that were used for selecting the depressive user are paciente psiquitrico con depresin crnica psychiatric patient with chronic depression example of a profile sentence that indicates depression colecciono errores traducidos a tweet depresivos y a uno que otro impulso de amor i gather error translated into depressing tweet and into one or another love impulse example of a profile sentence that doe not indicate depression once the user with profile sentence indicating depression had been retrieved their twitter timeline were collected only those user having in their timeline at least tweet that suggested sign of depression were retained for further analysis for each user the selection of these tweet wa performed by manually inspecting the tweet of the user complete timeline in reverse temporal order starting from the most recent one to the oldest tweet of the timeline retrieved by mean of the twitter api finally a total number of tweet issued by the depressive user suggesting sign of depression were detected and used for the analysis this set of tweet provided u with the depressive tweet dataset which wa used to analyze linguistic feature of tweet showing sign of depression it ha to be mentioned that these tweet were not to be included in the depressive user dataset see figure at the same time more than tweet were also collected in june such tweet were gathered by listening to the public twitter stream during this time span by only considering tweet with spanish textual content a detected by twitter language identification support given that twitter requires more restrictive filter than just the language of the tweet we used a list of the most frequently used spanish word stopwords to retrieve all tweet that included or more of these word the vast majority of spanish tweet should match this criterion a sample of user who did not mention in their profile the word depression and it derivation were selected randomly from the tweet the complete timeline of these user were compiled tweet which were reduced to once retweets were removed these tweet constituted the control dataset to identify the language of a tweet we relied on the language automatically identified by twitter for each tweet selecting tweet in spanish it ha to be noted that these data can contain some tweet from unidentified depressive user
data wa collected from cup of tea an anonymous online chatbased peer support community for emotional distress user agree at signup that their data may be used for the purpose of research all the data used for the current study wa anonymous and securely stored this research wa performed in line with the ethical and privacy protocol outlined in detail in benton et al data from cup take the form of written dialogue between user of the service and volunteer who are trained a active listener a fragment of an exchange between the user of the service u and the volunteer v might go a follows for the analysis reported in this paper we used only text generated by user of the service not the volunteer providing peer support user who reported depression a their primary concern at sign up were eligible for inclusion in analysis our original sample wa comprised of conversation involving unique user user were excluded from the sample if they did not indicate their culture or if they selected other this resulted in the exclusion of and user respectively the original sample also included user identifying a native american or american indian this group wa excluded from analysis since the majority of the data among these user wa not english this resulted in the removal of user leaving a total sample size of
selection criterion and data scope to understand the impact of cultural difference on how individual use online mental health platform we begin our analysis by creating a dataset of user from different national community on talklife a support platform with over half a million user for this analysis due to the fact that most research in cscw on mental health online ha been done either agnostic of cultural context or in a western context we choose to focus on user from nonwestern country following zhang et al a researcher located in the global south and with lived experience interacting with the health system and diverse explanatory model of mental illness we believe that moving the focus of cscw and cscwadjacent mental health research away from the west is crucial to better meet the need of people often underserved by the medical system to create these subgroup of user we choose the three nonwestern country with the highest user population on talklife or india malaysia and the philippine guided by the rich amount of literature on the unique nuance to mental health expression for each country we examine the national identity linguistic and behaviorbased difference of use between each user subgroup in particular this research note that a a result of cultural norm around the sharing of distress and alternative conceptualization of mental illness in india malaysia and the philippine symptom are often expressed in somatic and religious term a opposed to traditionally clinical or psychiatric term we choose to analyze each subgroup at the national level for both theoretical and practical reason on a theoretical level in past work in the medical anthropology of mental health national identity ha commonly been used for a approximate level of analysis for cultural identity additionally on a more practical level each user country wa determined using their ip address by talklife and shared with u in an useranonymized dataset inferring a more precise location could potentially compromise user anonymity a discussed in past work and did not seem to have any more significant value for our analysis of cultural difference than analysis at the national level we analyze data from indian user malaysian user and filipino user a shown in table collectively we refer to these country a the minority sample a a comparison set we construct a random sample of all thread on talklife and refer to it a the majority sample due to the relative prevalence of user from western englishspeaking country in talklife most of the thread in the majority sample include post from country such a the usa uk and canada indian are the largest nonwestern minority subgroup on talklife data wa sampled from may to june following this crossnational analysis to see if our broader result on talklife generalize to a differently structured online mental health community we picked the largest western country the united state and the largest nonwestern country india represented on cup a similar support platform with more than user actively using the platform each week using cup data we repeat our analysis testing for the same cultural difference we found in our talklife sample for this analysis we were provided a sample of data on activity from indian user and american user a shown in table unlike our sample of talklife user this dataset is not a random sample there is an upsampling of indian user to ensure that we have data from a sufficient number of indian in the dataset like on talklife indian are the largest nonwestern minority subgroup on cup we focus on indian user due to a lack of sufficient data on user from malaysia or the philippine data wa sampled from march august defining cultural identity and use of clinical language in this work we examine the relationship between cultural identity and use of online mental health support forum to do so we leverage tomlinsons definition of cultural identity a self and communal definition based around specific usually politically inflected differentiation gender sexuality class religion race and ethnicity nationality particularly looking at the aspect that of modern cultural identity that run along national line a delineated by hall et al a a diverse and amorphous form of identity cultural identity can often intersect and interact with other form of identity including religious or ethnic identity however in the absence of direct information about religious or ethnic identity based on the data available we use national identity a a proxy for cultural identity additionally following schlesinger et al call for more intersectional analysis and method within hci we also include analysis of adjacent and intersecting identity when relevant including religious identity to analyze clinical language we use a broader definition of clinical language than just specific medical diagnosis following method used in past work to analyze antidepressant related language we create a dataset of clinical mental health language including unigrams bigram and trigram from a list of mental disorder a defined by the international classification of disease icd and diagnostic and statistical manual of mental disorder dsm we also included all unigrams from the macmillan dictionary list of word used to describe illness and disease both specifically for mental illness and general illness a a result we include unigrams like night from night terror or sleep from sleep disorder a these are often correlated with specific symptom of mental illness or distress such a sleep issue or being awake at night this included any clinically common abbreviation for mental disorder such a ocd for obsessive compulsive disorder or bpd for borderline personality disorder shorthand for disorder commonly used by online community such a proana a used in proeating disorder community were not included due to the difficulty in finding an exhaustive list of these term across disorder we choose to use term from and associated with dsm and icd categorized disorder a a result of the common usage of these framework globally throughout our analysis of these varied factor we use to represent mean and to represent standard deviation constraint limitation and tradeoff cultural identity can exist at many different and intersecting level including subculture and subcommunities within the larger umbrella of a cultural identity a a result for the purpose of this analysis we had to adopt some constraint in order to do a meaningful and specific analysis one large limiting constraint that we chose for this study is to use national identity at the state level a a proxy for cultural identity though a major and formative part of modern cultural identity a argued by both hall and tomlinson each country we analyze is incredibly diverse with many individual cultural identity that both intersect and diverge from a greater national identity a more rich analysis of these other form of cultural identity is beyond the scope of this work but could lead to richer conclusion about the nature of cultural identity in online mental health support community particularly with regard to cultural difference between user with the same national identity additionally to stay consistent between analysis a a result of a lack of data on user from malaysia and the philippine we only analyze user in india on cup and extend these finding to the experience of being part of a minority group on an online mental health forum we draw validity for these exploratory finding from similar consistent pattern we observe between indian malaysian and filipino user but a deeper analysis with a larger dataset is likely necessary to determine when and for which minority community these conclusion do not hold true additionally while we construct clinical language through use of the commonly used dsm and icd both framework of illness categorization have significant limitation particularly in the country we have selected for example there are both mental health disorder that are culturebound a well a mental health language that is used in different way within the specific country we analyze such a depression often being an umbrella term for all mental illness additionally it is clear that online support community often develop their own cultural norm and language around mental health and a deeper understanding of how this play out on talklife and cup is neither the focus nor within the scope of this work in this work we intentionally use standard clinical and medical term for mental health disorder in our analysis of clinical language a detailed in past anthropological research it is theorized that the use of medical and clinical language is representative of a medicalized explanatory model of illness and we frame use of this language across culture a a approximate signifier of a greater awareness of the presence of a mental disorder a opposed to conceptualizing distress a stress tension or depression for our analysis we strictly analyzed post that were in the latin alphabet with almost all post on both talklife and cup being in english however a both malay and tagalog are most commonly written in the latin script and since it is common for user from india speaker to use romanized version of indian language online it is possible that a small minority of post in our analysis were text in a different language however a confirmed by only seeing english word used in our analysis of the top ngrams among each user subgroup it is clear that english is the predominant language on both platform though beyond the immediate scope of this work a greater analysis of nonenglish codeswitching on these platform could lead to a deeper understanding of the impact of interaction on expression between user with the same national identity but different language preference
many topic modeling algorithm exist including latent semantic indexing latent dirichlet allocation and nonnegative matrix factorization in this work we turn our attention to wordvec which ha been argued to have many advantage over these earlier algorithm wordvec describes two implementation of a shallow neural network the continuous bag of word cbow model and the skipgram model we focus on the skipgram model in this work which learns vector representation of word by predicting neighboring word in a text see fig
rmn is a recursive neural network designed to model relationship between pair of entity from text each relationship is represented at a given point in time a a vector of weight over k descriptor entity that form a relationship do not need to be of the same class for example in this work we model the relationship between a user and the community in which she interacts each post or comment corresponds to a different instant word are represented a embeddings of dimension p that is each word w of a vocabulary v is a vector in rp user and community are represented by embeddings of dimension u and c respectively a in previous work we generated embeddings using glove the descriptor obtained from rmn are vector in rp allowing u to find the closest word to each descriptor the post or comment representation is denoted by vpost rp this vector is the average of the word embeddings contained in the post the representation of user and community are denoted by vuser and vcomm for each post or comment rmn take a input a vector v rp uc obtained by concatenating vpost vuser and vcomm these vector are combined through the weight of the neural network to obtain a representation dt rk of the relationship between the user and the community at that particular time rmn us a smoothing parameter to avoid abrupt change in the representation of the same relation in consecutive instant dt and dt the descriptor array r rkp is used for attempting to reconstruct the post vpost by making rt rdt rmn parameter weight and matrix of descriptor are trained in order to maximize an objective function that aim to approximate rt and vpost while retaining some distance between rt and other randomly sampled post see for more detail on rmn the input data for rmn wa preprocessed a follows first we removed all post and comment marked a deleted or removed standard stopwords using the nltk library punctuation and accent second for each subreddit we removed post and comment from user who performed le than activity post or comment following the methodology presented in finally we selected the word that appear at least once in each of the four subreddits analyzed seeking to find similarity in the way people express themselves when discussing mental health disorder the final subset of data analyzed by rmn is composed of unique word post and comment
